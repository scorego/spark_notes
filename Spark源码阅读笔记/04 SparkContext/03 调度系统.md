> `TaskScheduler`负责请求集群管理器给应用程序分配并运行Executor（一级调度）、给任务分配Executor并运行任务（二级调度），可以看做是任务调度的客户端。`DAGScheduler`主要用于在任务正式交给`TaskSchedulerImpl`之前做一些准备工作，包括创建Job、将DAG中的RDD划分为不同的Stage、提交Stage等。
>
> `SparkContext`中初始化`SchedulerBackend`和` TaskScheduler`的代码如下：
>
> ```scala
> // Create and start the scheduler
>     val (sched, ts) = SparkContext.createTaskScheduler(this, master, deployMode)
>     _schedulerBackend = sched
>     _taskScheduler = ts
>     _dagScheduler = new DAGScheduler(this)
>     _heartbeatReceiver.ask[Boolean](TaskSchedulerIsSet)
> ```
>
> 

Spark资源调度分为两层：第一层是集群管理器将资源分配给Application；第二层是Application进一步将资源分配给各个Task。这里所说的调度系统指的是第二层，主要由`DAGScheduler`和`TaskScheduler`构成，工作流程如下：

1. build operator DAG

   用户提交的Job将首先被转换为一系列RDD，并由RDD之间的依赖关系构建DAG，然后将DAG提交到调度系统。

2. split graph into stages of tasks

   `DAGScheduler`接收由RDD构成的DAG，将RDD划分到不同的Stage（类型有`ResultStage`和`ShuffleMapStage`）。根据Stage的不同类型，创建不同类型的Task（`ResultTask`和`ShuffleMapTask`）。每个Stage将因为未完成Partition的多少，创建零到多个Task。`DAGScheduler`最后将每个Stage中的Task以任务集合(`TaskSet`)的形式提交给`TaskScheduler`。

3. launch tasks via cluster manager

   使用集群管理器分配资源与任务调度，对于失败的任务有一定的重试和容错机制。`TaskScheduler`接收`TaskSet`，创建`TaskSetManager`对其进行管理，并将此`TaskSetManager`添加到调度池中，最后对Task的调度交给调度后端接口`SchedulerBackend`处理。`SchedulerBackend`首先申请`TaskScheduler`，按照调度算法（FIFO或者FAIR）对调度池中的所有`TaskSetManager`进行排序，然后对`TaskSet`按照最大本地性原则分配资源，最后在各个分配的节点上运行`TaskSet`中的Task。

4. execute tasks

   执行任务，并将任务的中间结果和最终结果存入存储体系。

