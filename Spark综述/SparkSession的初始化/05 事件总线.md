> `ListenerBus`特质是事件总线的意思，事件总线可以接受事件并将事件提交给对应的监听器。

`ListenerBus`是个泛型特质，泛型参数为`[L <: AnyRef, E]`，其中`L`是代表监听器，`E`代表事件。

```scala
package org.apache.spark.util

/**
 * An event bus which posts events to its listeners.
 */
private[spark] trait ListenerBus[L <: AnyRef, E] extends Logging {

    // 维护所有注册的监听器，Timer是com.codahale.metrics.Timer类
    private[this] val listenersPlusTimers = new CopyOnWriteArrayList[(L, Option[Timer])]

    private lazy val env = SparkEnv.get

    private lazy val logSlowEventEnabled = if (env != null) {
            // "spark.scheduler.listenerbus.logSlowEvent"
            env.conf.get(config.LISTENER_BUS_LOG_SLOW_EVENT_ENABLED)
        } else {
            false
        }

    private lazy val logSlowEventThreshold = if (env != null) {
            // "spark.scheduler.listenerbus.logSlowEvent.threshold"
            env.conf.get(config.LISTENER_BUS_LOG_SLOW_EVENT_TIME_THRESHOLD)
        } else {
            Long.MaxValue
        }

    final def addListener(listener: L): Unit = {
        listenersPlusTimers.add((listener, getTimer(listener)))
    }

    final def removeListener(listener: L): Unit = {
        listenersPlusTimers.asScala.find(_._1 eq listener)
        	.foreach { listenerAndTimer => listenersPlusTimers.remove(listenerAndTimer) }
    }
    final def removeAllListeners(): Unit = { listenersPlusTimers.clear() }

    protected def doPostEvent(listener: L, event: E): Unit

    def postToAll(event: E): Unit = {
        // JavaConverters can create a JIterableWrapper if we use asScala.
        // However, this method will be called frequently. To avoid the wrapper cost, here we use Java Iterator directly.
        val iter = listenersPlusTimers.iterator
        while (iter.hasNext) {
            val listenerAndMaybeTimer = iter.next()
            val listener = listenerAndMaybeTimer._1
            val maybeTimer = listenerAndMaybeTimer._2
            val maybeTimerContext = if (maybeTimer.isDefined) { maybeTimer.get.time() } else { null }
            lazy val listenerName = Utils.getFormattedClassName(listener)
            try {
                doPostEvent(listener, event)
                if (Thread.interrupted()) {
                    // We want to throw the InterruptedException right away so we can associate the interrupt
                    // with this listener, as opposed to waiting for a queue.take() etc. to detect it.
                    throw new InterruptedException()
                }
            } catch {
                case ie: InterruptedException =>
                    logError(s"Interrupted while posting to ${listenerName}. Removing that listener.", ie)
                    removeListenerOnError(listener)
                case NonFatal(e) if !isIgnorableException(e) =>
                	logError(s"Listener ${listenerName} threw an exception", e)
            } finally {
                if (maybeTimerContext != null) {
                    val elapsed = maybeTimerContext.stop()
                    if (logSlowEventEnabled && elapsed > logSlowEventThreshold) {
                        logInfo(s"Process of event ${redactEvent(event)} by listener ${listenerName} took " +
                                s"${elapsed / 1000000000d}s.")
                    }
                }
            }
        }
    }

    ...
}
```

```scala
private[spark] trait ListenerBus[L <: AnyRef, E] extends Logging
	private[sql] class ExecutionListenerBus => ListenerBus[QueryExecutionListener, SparkListenerSQLExecutionEnd]

	class ExternalCatalogWithListener => ListenerBus[ExternalCatalogEventListener, ExternalCatalogEvent]

	class ExternalCatalogWithListener => ListenerBus[ExternalCatalogEventListener, ExternalCatalogEvent]

	private[spark] trait SparkListenerBus => ListenerBus[SparkListenerInterface, SparkListenerEvent]
		private class AsyncEventQueue => SparkListenerBus
		private[spark] class ReplayListenerBus => SparkListenerBus

	private[streaming] class StreamingListenerBus => ListenerBus[StreamingListener, StreamingListenerEvent]

	class StreamingQueryListenerBus => ListenerBus[StreamingQueryListener, StreamingQueryListener.Event]
```

`SparkListenerBus`用于将`SparkListenerEvent`类型的事件投递到`SparkListenerInterface`类型的监听器，它有如下两种实现：

- `AsyncEventQueue`

  An asynchronous queue for events. All events posted to this queue will be delivered to the child listeners in a separate thread.

- `ReplayListenerBus` 

  A SparkListenerBus that can be used to replay events from serialized event data.

# 一、 `SparkListenerBus`

```scala
package org.apache.spark.scheduler

/**
 * A [[SparkListenerEvent]] bus that relays [[SparkListenerEvent]]s to its listeners
 */
private[spark] trait SparkListenerBus extends ListenerBus[SparkListenerInterface, SparkListenerEvent] {

    protected override def doPostEvent(listener: SparkListenerInterface, event: SparkListenerEvent): Unit = {
        event match {
            case stageSubmitted: SparkListenerStageSubmitted => listener.onStageSubmitted(stageSubmitted)
            case stageCompleted: SparkListenerStageCompleted => listener.onStageCompleted(stageCompleted)
            case jobStart: SparkListenerJobStart => listener.onJobStart(jobStart)
            case jobEnd: SparkListenerJobEnd => listener.onJobEnd(jobEnd)
            case taskStart: SparkListenerTaskStart => listener.onTaskStart(taskStart)
            case taskGettingResult: SparkListenerTaskGettingResult => listener.onTaskGettingResult(taskGettingResult)
            case taskEnd: SparkListenerTaskEnd => listener.onTaskEnd(taskEnd)
            case environmentUpdate: SparkListenerEnvironmentUpdate => listener.onEnvironmentUpdate(environmentUpdate)
            case blockManagerAdded: SparkListenerBlockManagerAdded => listener.onBlockManagerAdded(blockManagerAdded)
            case blockManagerRemoved: SparkListenerBlockManagerRemoved => listener.onBlockManagerRemoved(blockManagerRemoved)
            case unpersistRDD: SparkListenerUnpersistRDD => listener.onUnpersistRDD(unpersistRDD)
            case applicationStart: SparkListenerApplicationStart => listener.onApplicationStart(applicationStart)
            case applicationEnd: SparkListenerApplicationEnd => listener.onApplicationEnd(applicationEnd)
            case metricsUpdate: SparkListenerExecutorMetricsUpdate => listener.onExecutorMetricsUpdate(metricsUpdate)
            case stageExecutorMetrics: SparkListenerStageExecutorMetrics =>
            	listener.onStageExecutorMetrics(stageExecutorMetrics)
            case executorAdded: SparkListenerExecutorAdded => listener.onExecutorAdded(executorAdded)
            case executorRemoved: SparkListenerExecutorRemoved => listener.onExecutorRemoved(executorRemoved)
            case executorBlacklistedForStage: SparkListenerExecutorBlacklistedForStage =>
            	listener.onExecutorBlacklistedForStage(executorBlacklistedForStage)
            case nodeBlacklistedForStage: SparkListenerNodeBlacklistedForStage =>
            	listener.onNodeBlacklistedForStage(nodeBlacklistedForStage)
            case executorBlacklisted: SparkListenerExecutorBlacklisted =>
            	listener.onExecutorBlacklisted(executorBlacklisted)
            case executorUnblacklisted: SparkListenerExecutorUnblacklisted =>
            	listener.onExecutorUnblacklisted(executorUnblacklisted)
            case nodeBlacklisted: SparkListenerNodeBlacklisted =>
            	listener.onNodeBlacklisted(nodeBlacklisted)
            case nodeUnblacklisted: SparkListenerNodeUnblacklisted =>
            	listener.onNodeUnblacklisted(nodeUnblacklisted)
            case executorExcludedForStage: SparkListenerExecutorExcludedForStage =>
            	listener.onExecutorExcludedForStage(executorExcludedForStage)
            case nodeExcludedForStage: SparkListenerNodeExcludedForStage =>
            	listener.onNodeExcludedForStage(nodeExcludedForStage)
            case executorExcluded: SparkListenerExecutorExcluded =>
            	listener.onExecutorExcluded(executorExcluded)
            case executorUnexcluded: SparkListenerExecutorUnexcluded =>
            	listener.onExecutorUnexcluded(executorUnexcluded)
            case nodeExcluded: SparkListenerNodeExcluded =>
            	listener.onNodeExcluded(nodeExcluded)
            case nodeUnexcluded: SparkListenerNodeUnexcluded =>
            	listener.onNodeUnexcluded(nodeUnexcluded)
            case blockUpdated: SparkListenerBlockUpdated =>
            	listener.onBlockUpdated(blockUpdated)
            case speculativeTaskSubmitted: SparkListenerSpeculativeTaskSubmitted =>
            	listener.onSpeculativeTaskSubmitted(speculativeTaskSubmitted)
            case unschedulableTaskSetAdded: SparkListenerUnschedulableTaskSetAdded =>
            	listener.onUnschedulableTaskSetAdded(unschedulableTaskSetAdded)
            case unschedulableTaskSetRemoved: SparkListenerUnschedulableTaskSetRemoved =>
            	listener.onUnschedulableTaskSetRemoved(unschedulableTaskSetRemoved)
            case resourceProfileAdded: SparkListenerResourceProfileAdded =>
            	listener.onResourceProfileAdded(resourceProfileAdded)
            case _ => listener.onOtherEvent(event)
        }
    }

}
```

从代码来看，`SparkListenerBus`特质就是实现了`doPostEvent()`方法，通过对`SparkListenerEvent`事件进行匹配，执行`SparkListenerInterface`监听器的相应方法。

当有事件需要通知监听器的时候，可以调用`SparkListenerBus`的`postToAll()`方法(`ListenerBus`特质已经实现了该方法)，该方法遍历所有监听器并调用`SparkListenerBus`实现的`doPostEvent()`方法。`doPostEvent()`方法对事件类型进行匹配后调用监听器的不同方法，整个投递事件是一个同步调用。在监听器比较多的时候，整个过程会比较耗时。 `LiveListenerBus`是一个异步投递消息的实现。

# 二、 `LiveListenerBus`

`LiveListenerBus`在之前的版本继承了`SparkListenerBus`，自Spark 2.3后便不在实现`SparkListenerBus`特质。

- https://github.com/apache/spark/blob/branch-2.2/core/src/main/scala/org/apache/spark/scheduler/LiveListenerBus.scala
- https://github.com/apache/spark/blob/branch-2.3/core/src/main/scala/org/apache/spark/scheduler/LiveListenerBus.scala

`LiveListenerBus`实现了将`SparkListenerEvents`事件异步投递给`SparkListenerInterface`监听器。

```scala
package org.apache.spark.scheduler

/**
 * Asynchronously passes SparkListenerEvents to registered SparkListeners.
 *
 * Until `start()` is called, all posted events are only buffered. Only after this listener bus
 * has started will events be actually propagated to all attached listeners. This listener bus
 * is stopped when `stop()` is called, and it will drop further events after stopping.
 */
private[spark] class LiveListenerBus(conf: SparkConf) {...}

private[spark] object LiveListenerBus {
  // Allows for Context to check whether stop() call is made within listener thread
  val withinListenerThread: DynamicVariable[Boolean] = new DynamicVariable[Boolean](false)

  private[scheduler] val SHARED_QUEUE = "shared"

  private[scheduler] val APP_STATUS_QUEUE = "appStatus"

  private[scheduler] val EXECUTOR_MANAGEMENT_QUEUE = "executorManagement"

  private[scheduler] val EVENT_LOG_QUEUE = "eventLog"
}
```

